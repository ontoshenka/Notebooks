# Информация об отдельных блокнотах
1. `BuildVocab.ipynb` - разбиение отзывов на токены, лемматизация токенов, построение отображения вида "токен - число" (включая, разумеется, токен `<pad>` обозначающий отсутсвия слова или наличие неизвестного слова), приведение отзывов к последовательности чисел фиксированной длины
2. `Embeddings.ipynb` - этот блокнот стоит особняком в том смысле, что тут обученые вложения токенов с помощью skip-gram, а это пока нигде больше не использовалось
3. `Modeling.ipynb` - блокнот с непосредственно решением (точнее, работой в поисках решения) задачи
4. `Without neutrals.ipynb` - блокнот с решением этой же задачи, но без нейтральных отзывов. Призван убедиться, что палки в колёса в блокноте выше нам вставляют именно нейтральные отзывы

Никаких файлов с другими вещами (вроде самих данных, созданных словарей и т.д) не привожу поскольку они слишком много весят

# Что было сделано
Истратил кучу сил и времени на ворох непонятных ошибок, что генерировал tensorflow, перебрал 
ряд нейросетевых архитектур

# Грабли
Беды с пониманием каких размерностей данные какие слои принимают. Внимательно читайте документацию. Если корокто, то указывать первую размерность как None при определении нейросети не надо - tensorflow сделает это сам. Могу ошибатсья, но кажется, во всех остальных местах это делать надо.
И главное. Точность - это ОЧЕНЬ. Я повторяюсь: ОЧЕНЬ плохая метрика качества при условии несбалансированности выборки

# Чему я научился и что вынес в процессе работы
Разобрался с базовыми принципами работы с tensorflow. Такая вещь, как GradientTape меня, признаться, впечатлила, но применения в этом проекте ей, к сожалению, нет. Пощупал как изменяется время, необходимое на обучение сети изменяется в зависимости от количества рекурентных слоёв. Спойлер: 3 уже достаточно долго. Больше часа на эпоху на моей видеокарте (1660ti Max-Q design, 6 Gb). 

# Что можно сделать, чтоб улучшить результат 
1. Опробовать другие (в т.ч не рекурентные) архитектуры. Кажется, модели внимания должны отработать хорошо
2. Поварьировать веса классов 
3. Попробовать использовать предобученные вложение, тем самым отказавшись от Embedding слоя

Некоторые из вышеуказаных вариантов я ещё попробую в ближайшем будущем. Вы ведь забыли что было написано в `readme` в папочке HP, да?

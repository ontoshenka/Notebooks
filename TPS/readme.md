# Структура проекта

- `logs` - информация о испробованных моделях и условиях валидации. Удобно в случае, если когда-то получилась хорошая модель, но вспомнить как она получилась никак не выходит
- `figs` - визуализация некоторых решающих деревьев из блокнота в .png и .svg форматах
- `predictions` - предсказания построенных моделей на тестовом датасете

# Что было сделано
Больше всего сил ушло на чтение и неоднократное перечитывание [статьи, что описывает суть проблемы](https://www.frontiersin.org/articles/10.3389/fmicb.2020.00257/full). Правда, это же принесло больше всего удовольствия, ведь мне довелось убедиться в том, что я смогу понять данные из области, мой уровень компетенции в которой ограничивается осведомлённостью о том, что такая область знаний существует. Помимо всего прочего, пришлось немного подумать, чтоб прикрутить опцию, состоющую в применении метода главных компонент во время кросс-валидации по k блокам

# Грабли
Повторы в данных - зло, что в лучшем случае сильно искажает валидацию в сторону непонятно чего: получается, что при одном способе разбиение выборки на k блоков алгоритм показывает себя отлично, а при другом из рук вон плохо. Такой случай я назвал лучшим потому что в таком такой расклад сразу даёт понять, что что-то пошло не так и не остаётся ничего, кроме как возвращаться назад и искать ошибку. В худшем же случае, это приводит к переоценке качества алгоритма и при должной невнимательности этого можно долго не замечать

# Чему я научился и что вынес в процессе работы
Если тебе на блюдечке принесли документ, призванный дать исчерпывающее объяснение данным, нет ничего хуже, чем игнорировать его и пытаться что-то получить, ничего не понимая. Если такого документа нет, а область знаний, из которой пришли данные Вам не близка, такой документ стоит составить самому

# Что можно сделать, чтоб улучшить результат 
- Потюнить параметры CatBoost'a или найти алгоритм получше. Не исключено, что, например, нейросети покажут себя хорошо
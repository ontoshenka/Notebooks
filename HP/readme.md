# Структура проекта
- data - исходные данные
- processed_data - данные после EDA
- predictions - предсказания разных моделей на тестовом наборе
- logs - информация о испробованных моделях и условиях валидации. Удобно в случае, если когда-то получилась хорошая модель, но вспомнить как она получилась никак не выходит
- EDA.ipynb - некий бейзлайн разведочного анализа данных, изменения относительно которого предполагается описывать в логах

# Что было сделано

- Проведён разведочный анализ данных
- Были проверены некоторые статистические гипотезы
- "Неудобно" распределённые вещественнозначные переменные, которые можно было привести к нормальному распределению, были к нему приведены
- Были сгенерированы новые вещественнозначные признаки
- Реализована своя функция для валидации по k блокам и поиска по сетка за тем, чтоб удобнее отслеживать прогресс выполнения (с помощью tqdm) и иметь возможность по необходимости расширять функционал, что пригодилось в [другом проекте](https://github.com/ontoshenka/Notebooks/tree/master/TPS) 
- Был испробован ряд моделей, для каждой из которых был проведён тюнинг гиперпараметров

# TODO

1. Попробовать сравнивать модели другими методами (t-тест Стьюдента, сравнение с нулём попарных разностей скоров). Сделаю в ближайшие дни. Дело не в том, что я слишком ленив, а в том, что модели сравниваются на основании скора на отложенной выборке, в качестве который выступает kaggle, а там ограничение на submit'ы в сутки
2. Жёстко нагенерить ещё признаков 
3. Поварьировать "агрессивность" отбора категориальных признаков